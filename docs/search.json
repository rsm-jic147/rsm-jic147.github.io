[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nJiayin Chen\n\n\nApr 20, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, recipients were randomly assigned to different variations of the fundraising letter. Some were told their donation would be matched at a rate of 1:1, 2:1, or 3:1 by a “concerned fellow member,” up to a maximum matching amount ($25,000, $50,000, or $100,000). Others were part of the control group, which received no mention of a match. Suggested donation amounts were also varied to test the impact of different “ask” levels. The researchers found that simply including a match offer increased both donation rates and average amounts raised—but larger match ratios (2:1 or 3:1) did not generate significantly higher donations than the 1:1 match.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/index.html#introduction",
    "href": "blog/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, recipients were randomly assigned to different variations of the fundraising letter. Some were told their donation would be matched at a rate of 1:1, 2:1, or 3:1 by a “concerned fellow member,” up to a maximum matching amount ($25,000, $50,000, or $100,000). Others were part of the control group, which received no mention of a match. Suggested donation amounts were also varied to test the impact of different “ask” levels. The researchers found that simply including a match offer increased both donation rates and average amounts raised—but larger match ratios (2:1 or 3:1) did not generate significantly higher donations than the 1:1 match.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/index.html#data",
    "href": "blog/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset consists of 50,083 observations and 51 variables, drawn from a large-scale field experiment conducted by Karlan and List (2007) to study charitable giving behavior. Each observation represents a past donor who was randomly assigned to receive one of several fundraising letter treatments. These treatments varied in terms of match ratio, match threshold, and suggested donation amount.\nThe dataset includes:\nTreatment assignment variables, indicating whether individuals were in the control group or received a match offer, and if so, the match ratio (e.g., 1:1, 2:1, 3:1) and threshold size ($25,000, $50,000, $100,000, or unstated).\nSuggested donation amounts based on individuals’ previous giving history, which were randomly varied in the letters.\nDonation outcomes, including whether the individual gave and how much they gave.\nDemographic and donation history, such as gender, relationship status, number of years since the first donation, and prior donation frequency.\nGeographic and political context, with data on the political leaning of the recipient’s state and county (e.g., red/blue states), as well as census-linked socioeconomic indicators like median income, education, and urbanicity at the zip code level.\n\nimport pandas as pd\n\n# Load the Stata file\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Show the first few rows\nprint(df.head())\n\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\n\n# Variables to test for balance\nvariables = ['mrm2', 'freq', 'years', 'female', 'ave_hh_sz', 'median_hhincome']\n\nprint(\"=== Balance Check: Treatment vs Control ===\\n\")\n\nfor var in variables:\n    # Drop missing for current variable\n    df_clean = df[[var, 'treatment']].dropna()\n\n    # Split by group\n    treat = df_clean[df_clean['treatment'] == 1][var]\n    control = df_clean[df_clean['treatment'] == 0][var]\n\n    # Sample sizes\n    n1 = len(treat)\n    n0 = len(control)\n\n    # Means\n    mean1 = treat.mean()\n    mean0 = control.mean()\n\n    # Variances\n    var1 = treat.var(ddof=1)\n    var0 = control.var(ddof=1)\n\n    # T-statistic\n    se = np.sqrt(var1 / n1 + var0 / n0)\n    t_stat = (mean1 - mean0) / se\n    df_deg = min(n1 - 1, n0 - 1)\n    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df_deg))\n\n    # Print results\n    print(f\"Variable: {var}\")\n    print(f\"  Control Mean:   {mean0:.3f}\")\n    print(f\"  Treatment Mean: {mean1:.3f}\")\n    print(f\"  t-statistic:    {t_stat:.3f}\")\n    print(f\"  p-value:        {p_val:.4f}\")\n    print(f\"  Statistically significant? {'YES' if p_val &lt; 0.05 else 'NO'}\\n\")\n\n=== Balance Check: Treatment vs Control ===\n\nVariable: mrm2\n  Control Mean:   12.998\n  Treatment Mean: 13.012\n  t-statistic:    0.120\n  p-value:        0.9049\n  Statistically significant? NO\n\nVariable: freq\n  Control Mean:   8.047\n  Treatment Mean: 8.035\n  t-statistic:    -0.111\n  p-value:        0.9117\n  Statistically significant? NO\n\nVariable: years\n  Control Mean:   6.136\n  Treatment Mean: 6.078\n  t-statistic:    -1.091\n  p-value:        0.2753\n  Statistically significant? NO\n\nVariable: female\n  Control Mean:   0.283\n  Treatment Mean: 0.275\n  t-statistic:    -1.754\n  p-value:        0.0795\n  Statistically significant? NO\n\nVariable: ave_hh_sz\n  Control Mean:   2.427\n  Treatment Mean: 2.430\n  t-statistic:    0.823\n  p-value:        0.4103\n  Statistically significant? NO\n\nVariable: median_hhincome\n  Control Mean:   54921.094\n  Treatment Mean: 54763.169\n  t-statistic:    -0.743\n  p-value:        0.4573\n  Statistically significant? NO\n\n\n\nEach of these variables shows no statistically significant difference at the 95% confidence level, including female, which has the lowest p-value (0.0795) but still does not cross the conventional threshold for significance.\nThese findings replicate the results shown in Table 1 of Karlan & List (2007). The table in the original paper is designed to demonstrate that randomization worked: treatment and control groups are statistically equivalent in expectation across observable characteristics.\nBy showing balance across variables like mrm2, freq, female, and neighborhood demographics (median_hhincome, ave_hh_sz), we can be confident that:\n\nThere is no selection bias\nAny differences in donation outcomes observed later can be causally attributed to the treatment"
  },
  {
    "objectID": "blog/project1/index.html#experimental-results",
    "href": "blog/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n## bar plot\n\nimport matplotlib.pyplot as plt\n\n# Calculate proportions\ngave_by_group = df[['gave', 'treatment']].dropna().groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\nproportions = [gave_by_group[0], gave_by_group[1]]\n\n# Create bar plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(labels, proportions)\nplt.ylabel('Proportion Who Donated')\nplt.title('Donation Rates by Group')\nplt.ylim(0, max(proportions) + 0.05)\n\n# Add value labels\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{yval:.3f}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# t-tes\n\n# T-test and regression for the binary outcome 'gave'\n\n# Drop missing values for 'gave' and 'treatment'\ngave_data = df[['gave', 'treatment']].dropna()\n\n# Split into treatment and control\ngave_treatment = gave_data[gave_data['treatment'] == 1]['gave']\ngave_control = gave_data[gave_data['treatment'] == 0]['gave']\n\n# Manual t-test\nn1 = len(gave_treatment)\nn0 = len(gave_control)\nmean1 = gave_treatment.mean()\nmean0 = gave_control.mean()\nvar1 = gave_treatment.var(ddof=1)\nvar0 = gave_control.var(ddof=1)\nse = np.sqrt(var1/n1 + var0/n0)\nt_stat = (mean1 - mean0) / se\ndf_deg = min(n1 - 1, n0 - 1)\np_val = 2 * (1 - stats.t.cdf(abs(t_stat), df_deg))\n\n# Bivariate linear regression\nX = sm.add_constant(gave_data['treatment'])\ny = gave_data['gave']\ngave_model = sm.OLS(y, X).fit()\n\n{\n    \"t_test\": {\n        \"mean_treatment\": mean1,\n        \"mean_control\": mean0,\n        \"t_statistic\": t_stat,\n        \"p_value\": p_val\n    },\n    \"regression_coef\": gave_model.params['treatment'],\n    \"regression_pval\": gave_model.pvalues['treatment'],\n    \"regression_summary\": gave_model.summary().as_text()\n}\n# --- Print nicely formatted results ---\n\nprint(\"=== T-Test Results ===\")\nprint(f\"Treatment group donation rate: {mean1:.4f}\")\nprint(f\"Control group donation rate:   {mean0:.4f}\")\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value:     {p_val:.4f}\")\n\nprint(\"\\n=== Regression Results ===\")\nprint(f\"Estimated treatment effect (coef): {gave_model.params['treatment']:.4f}\")\nprint(f\"Standard error:                   {gave_model.bse['treatment']:.4f}\")\nprint(f\"T-statistic:                      {gave_model.tvalues['treatment']:.3f}\")\nprint(f\"P-value:                          {gave_model.pvalues['treatment']:.4f}\")\n\n=== T-Test Results ===\nTreatment group donation rate: 0.0220\nControl group donation rate:   0.0179\nT-statistic: 3.209\nP-value:     0.0013\n\n=== Regression Results ===\nEstimated treatment effect (coef): 0.0042\nStandard error:                   0.0013\nT-statistic:                      3.101\nP-value:                          0.0019\n\n\nThese results align with Table 2A, Panel A of Karlan & List (2007), which also shows a higher donation rate in the treatment group.\nWhile the increase in donation probability is small in absolute terms, it is statistically meaningful. This tells us something important about human behavior: small cues or framing changes (like mentioning a matching grant) can make people more likely to give.\nIn particular, this experiment shows that:\n\nPsychological nudges, such as the presence of a matching donor, can shift decisions.\nEven minimal changes in language or perceived impact can meaningfully influence behavior.\nPeople respond to social signals of generosity, even if the financial incentive is unchanged.\n\nFrom a behavioral perspective, this suggests: - People are more likely to give when they believe their donation will be matched — it increases the perceived impact of their gift. - This change in behavior is not driven by financial incentives alone (since the match isn’t actually paid to them) but by psychological framing and the feeling that their donation will be “worth more.”\nIn the context of the Karlan & List study, this result supports the idea that small nudges, such as the presence of a matching grant, can meaningfully shift behavior — a key finding for fundraisers and behavioral economists alike.\n\n## replicate of table 3\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Clean the data\ndf_clean = df[['gave', 'treatment']].dropna()\n\n# Probit regression\nprobit_model = smf.probit('gave ~ treatment', data=df_clean).fit(disp=0)\n\n# Get marginal effects\nmfx = probit_model.get_margeff(method='dydx').summary_frame()\n\n# Display results\nprint(\"\\n=== Probit Regression (Marginal Effects) ===\")\nprint(mfx)\n\n\n=== Probit Regression (Marginal Effects) ===\n              dy/dx  Std. Err.         z  Pr(&gt;|z|)  Conf. Int. Low  \\\ntreatment  0.004313   0.001389  3.104419  0.001907         0.00159   \n\n           Cont. Int. Hi.  \ntreatment        0.007036  \n\n\nTo replicate Table 3, Column 1 from Karlan & List (2007), I ran a probit regression where the outcome variable was whether an individual made any charitable donation (gave) and the explanatory variable was assignment to the treatment or control group.\nI then calculated marginal effects to make the results directly comparable to those reported in the paper.\nThe estimated marginal effect of the treatment was 0.0043, with a standard error of 0.0014 and a p-value of 0.0019. This means that being assigned to the treatment group increased the probability of donating by about 0.43 percentage points. The result is statistically significant at the 1% level, matching the original paper’s finding of a 0.004* effect.\nThis confirms the authors’ key result: framing the ask as part of a matching donation offer has a measurable and statistically significant impact on giving behavior. Even though the increase in donation probability is relatively small, it provides compelling evidence that simple nudges — like mentioning a match — can influence real-world decisions in meaningful ways.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# t-test\nprint(df['ratio'].unique())\n\n# Filter to treatment group only with valid match ratio and donation status\ndf_filtered = df[(df['treatment'] == 1) & (df['gave'].notnull()) & (df['ratio'].isin([1, 2, 3]))]\n\n# Subset donation status by match ratio\ngave_1to1 = df_filtered[df_filtered['ratio'] == 1]['gave']\ngave_2to1 = df_filtered[df_filtered['ratio'] == 2]['gave']\ngave_3to1 = df_filtered[df_filtered['ratio'] == 3]['gave']\n\n# Compute mean response rates\nmeans = {\n    \"1:1\": gave_1to1.mean(),\n    \"2:1\": gave_2to1.mean(),\n    \"3:1\": gave_3to1.mean()\n}\n\n# Conduct pairwise t-tests\nt_2v1 = stats.ttest_ind(gave_2to1, gave_1to1, equal_var=False)\nt_3v1 = stats.ttest_ind(gave_3to1, gave_1to1, equal_var=False)\nt_3v2 = stats.ttest_ind(gave_3to1, gave_2to1, equal_var=False)\n\n# Print results\nprint(\"=== Mean Donation Rates ===\")\nfor k, v in means.items():\n    print(f\"{k} match: {v:.4%}\")\n\nprint(\"\\n=== T-Test Results ===\")\nprint(f\"2:1 vs 1:1: t = {t_2v1.statistic:.3f}, p = {t_2v1.pvalue:.4f}\")\nprint(f\"3:1 vs 1:1: t = {t_3v1.statistic:.3f}, p = {t_3v1.pvalue:.4f}\")\nprint(f\"3:1 vs 2:1: t = {t_3v2.statistic:.3f}, p = {t_3v2.pvalue:.4f}\")\n\n# Plot response rates by match ratio\nplt.figure(figsize=(6, 4))\nplt.bar(means.keys(), means.values(), color=['#4daf4a', '#377eb8', '#984ea3'])\nplt.ylabel('Proportion Who Donated')\nplt.title('Donation Rates by Match Ratio')\n\n# Add value labels\nfor label, val in means.items():\n    plt.text(label, val + 0.0005, f'{val:.3%}', ha='center')\n\nplt.ylim(0, max(means.values()) + 0.01)\nplt.tight_layout()\nplt.show()\n\n['Control', 1, 2, 3]\nCategories (4, object): ['Control' &lt; 1 &lt; 2 &lt; 3]\n=== Mean Donation Rates ===\n1:1 match: 2.0749%\n2:1 match: 2.2633%\n3:1 match: 2.2733%\n\n=== T-Test Results ===\n2:1 vs 1:1: t = 0.965, p = 0.3345\n3:1 vs 1:1: t = 1.015, p = 0.3101\n3:1 vs 2:1: t = 0.050, p = 0.9600\n\n\n\n\n\n\n\n\n\nThe results fully support the authors’ interpretation on page 8.\n“While the match treatments relative to a control group increase the probability of donating, larger match ratios—$3:$1 and $2:$1—relative to a smaller match ratio ($1:$1) have no additional impact.”\nEven though the donation rates numerically increase with larger match ratios, the t-tests show these increases are not statistically significant.\n\n# Filter dataset: keep all rows with non-null 'gave' and any valid 'ratio'\ndf_ratio_all = df[df['gave'].notnull() & df['ratio'].isin(['Control', 1, 2, 3])].copy()\n\n# Ensure 'ratio' is treated as a categorical variable\ndf_ratio_all['ratio'] = df_ratio_all['ratio'].astype('category')\n\n# Run regression with ratio as a categorical predictor\nmodel = smf.ols('gave ~ C(ratio)', data=df_ratio_all).fit()\n\n# Display results\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Sun, 20 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        15:41:53   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0179      0.001     16.225      0.000       0.016       0.020\nC(ratio)[T.1]     0.0029      0.002      1.661      0.097      -0.001       0.006\nC(ratio)[T.2]     0.0048      0.002      2.744      0.006       0.001       0.008\nC(ratio)[T.3]     0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nTo assess how different match ratios affect the likelihood of donating, I ran a linear regression of gave (a binary indicator for whether a person donated) on a categorical variable representing the match ratio. This includes the control group (no match), as well as the 1:1, 2:1, and 3:1 match conditions.\nThe regression treats the control group as the baseline category. The coefficients on the 1:1, 2:1, and 3:1 match indicators reflect the difference in donation rates compared to the control group.\n\nThe intercept represents the average donation rate in the control group (i.e., the probability of giving when no match is offered).\nThe coefficients for 1:1, 2:1, and 3:1 indicate how much more likely someone is to donate under each match condition compared to control.\n\nIf these coefficients are statistically significant, we can conclude that the corresponding match offer increased the likelihood of giving relative to the control group.\n\n# data vs. regression\n\n# Step 1: Direct differences from the data\ngave_1 = df_ratio_all[df_ratio_all['ratio'] == 1]['gave']\ngave_2 = df_ratio_all[df_ratio_all['ratio'] == 2]['gave']\ngave_3 = df_ratio_all[df_ratio_all['ratio'] == 3]['gave']\n\ndirect_diff_21_vs_11 = gave_2.mean() - gave_1.mean()\ndirect_diff_31_vs_21 = gave_3.mean() - gave_2.mean()\n\n# Step 2: Use regression coefficients (relative to Control group)\ncoef_1 = model.params.get('C(ratio)[T.1]', 0)\ncoef_2 = model.params.get('C(ratio)[T.2]', 0)\ncoef_3 = model.params.get('C(ratio)[T.3]', 0)\n\nreg_diff_21_vs_11 = coef_2 - coef_1\nreg_diff_31_vs_21 = coef_3 - coef_2\n\n# Print results\nprint(\"=== Response Rate Differences ===\")\nprint(f\"2:1 vs 1:1 (Direct from data):       {direct_diff_21_vs_11:.4%}\")\nprint(f\"3:1 vs 2:1 (Direct from data):       {direct_diff_31_vs_21:.4%}\")\nprint(f\"2:1 vs 1:1 (From regression coef):   {reg_diff_21_vs_11:.4%}\")\nprint(f\"3:1 vs 2:1 (From regression coef):   {reg_diff_31_vs_21:.4%}\")\n\n=== Response Rate Differences ===\n2:1 vs 1:1 (Direct from data):       0.1884%\n3:1 vs 2:1 (Direct from data):       0.0100%\n2:1 vs 1:1 (From regression coef):   0.1884%\n3:1 vs 2:1 (From regression coef):   0.0100%\n\n\nThese values are nearly identical by both methods, confirming the robustness of the regression results. The 2:1 match rate yields a very small increase in response over 1:1, while the jump from 2:1 to 3:1 is virtually nonexistent. This reinforces the conclusion that larger match ratios beyond 1:1 do not meaningfully increase the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# t-test  vs bivariate\n# Filter for treatment and control groups with valid donation amounts\ndf_amount = df[df['amount'].notnull() & df['treatment'].isin([0, 1])]\n\n# Perform a t-test on donation amounts between treatment and control\namount_treatment = df_amount[df_amount['treatment'] == 1]['amount']\namount_control = df_amount[df_amount['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treatment, amount_control, equal_var=False)\n\n# Run a bivariate linear regression of amount on treatment\namount_model = smf.ols('amount ~ treatment', data=df_amount).fit()\namount_summary = amount_model.summary2().as_text()\n\n# Extract regression results\ncoef = amount_model.params['treatment']\npval = amount_model.pvalues['treatment']\nconf_int = amount_model.conf_int().loc['treatment'].tolist()\n\n{\n    \"t_test\": {\n        \"t_statistic\": t_stat,\n        \"p_value\": p_val\n    },\n    \"regression\": {\n        \"coef\": coef,\n        \"p_value\": pval,\n        \"95% CI\": conf_int\n    },\n    \"regression_summary\": amount_summary\n}\n\nprint(\"=== Effect of Treatment on Donation Amount ===\")\n\n# T-test results\nprint(\"\\nT-test comparing treatment vs. control:\")\nprint(f\"t-statistic: {t_stat:.3f}\")\nprint(f\"p-value:     {p_val:.4f}\")\n\n# Regression results\nprint(\"\\nRegression of amount on treatment:\")\nprint(f\"Treatment coefficient: {coef:.3f}\")\nprint(f\"p-value:              {pval:.4f}\")\nprint(f\"95% Confidence Interval: [{conf_int[0]:.3f}, {conf_int[1]:.3f}]\")\n\n=== Effect of Treatment on Donation Amount ===\n\nT-test comparing treatment vs. control:\nt-statistic: 1.918\np-value:     0.0551\n\nRegression of amount on treatment:\nTreatment coefficient: 0.154\np-value:              0.0628\n95% Confidence Interval: [-0.008, 0.315]\n\n\nThis analysis helps us understand whether the treatment affects not just the likelihood of donating, but also how much people give. The results from both the t-test and regression show that people in the treatment group donate about $0.15 more on average than those in the control group. However, this difference is only marginally statistically significant (p ≈ 0.06), and the confidence interval includes zero.\nFrom this, we learn that while the treatment (a matching offer) strongly influences whether people donate, it has a much weaker and less certain effect on the amount given. This suggests that the psychological nudge of a match offer may primarily work by encouraging participation — getting more people to donate — rather than motivating donors to give significantly more money.\n\n## limited to donate\n\n# Filter to include only donors (gave = 1) with valid amount and treatment status\ndf_positive_donors = df[(df['gave'] == 1) & (df['amount'].notnull()) & (df['treatment'].isin([0, 1]))]\n\n# T-test: compare average donation amount between treatment and control groups among donors only\namount_treatment = df_positive_donors[df_positive_donors['treatment'] == 1]['amount']\namount_control = df_positive_donors[df_positive_donors['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treatment, amount_control, equal_var=False)\n\n# Regression: amount ~ treatment among donors\ndonor_model = smf.ols('amount ~ treatment', data=df_positive_donors).fit()\ncoef = donor_model.params['treatment']\npval = donor_model.pvalues['treatment']\nconf_int = donor_model.conf_int().loc['treatment'].tolist()\nsummary_text = donor_model.summary2().as_text()\n\n{\n    \"t_test\": {\n        \"t_statistic\": t_stat,\n        \"p_value\": p_val\n    },\n    \"regression\": {\n        \"coef\": coef,\n        \"p_value\": pval,\n        \"95% CI\": conf_int\n    },\n    \"regression_summary\": summary_text\n}\nprint(\"=== Effect of Treatment on Donation Amount (Among Donors Only) ===\")\n\n# T-test results\nprint(\"\\nT-test:\")\nprint(f\"t-statistic: {t_stat:.3f}\")\nprint(f\"p-value:     {p_val:.4f}\")\n\n# Regression results\nprint(\"\\nRegression:\")\nprint(f\"Treatment coefficient:     {coef:.3f}\")\nprint(f\"p-value:                   {pval:.4f}\")\nprint(f\"95% Confidence Interval:   [{conf_int[0]:.3f}, {conf_int[1]:.3f}]\")\n\n=== Effect of Treatment on Donation Amount (Among Donors Only) ===\n\nT-test:\nt-statistic: -0.585\np-value:     0.5590\n\nRegression:\nTreatment coefficient:     -1.668\np-value:                   0.5615\n95% Confidence Interval:   [-7.305, 3.968]\n\n\nInterpretation of Regression Coefficient (Among Donors Only)\nThe regression coefficient on treatment is -1.668, meaning that among those who donated, individuals in the treatment group gave about $1.67 less on average than those in the control group. However, this difference is not statistically significant (p = 0.561), and the confidence interval ([-7.31, 3.97]) includes zero, indicating high uncertainty in the estimate.\nThis tells us that conditional on donating, the treatment had no clear effect on the amount given.\nDoes the Coefficient Have a Causal Interpretation?\nNo — this coefficient does not have a causal interpretation. By restricting the analysis to donors only, we introduce selection bias, because treatment status may influence the likelihood of appearing in this subset (i.e., whether someone donates). Since the treatment affects who is included in the analysis, the estimated difference in donation amounts is not a valid causal estimate.\nInstead, this result is descriptive: it tells us that among donors, there is no significant difference in how much people gave depending on whether they were in the treatment group or not.\n\n## make 2 plot\n\n# Filter for donors with non-zero donation amounts and treatment assignment\ndf_donors = df[(df['gave'] == 1) & (df['amount'] &gt; 0) & (df['treatment'].isin([0, 1]))]\n\n# Split into control and treatment groups\ncontrol_donors = df_donors[df_donors['treatment'] == 0]['amount']\ntreatment_donors = df_donors[df_donors['treatment'] == 1]['amount']\n\n# Compute means\nmean_control = control_donors.mean()\nmean_treatment = treatment_donors.mean()\n\n# Plot histograms side by side\nfig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\n# Control group histogram\naxes[0].hist(control_donors, bins=30, color='lightgray', edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean = ${mean_control:.2f}')\naxes[0].set_title('Control Group: Donation Amounts')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\n\n# Treatment group histogram\naxes[1].hist(treatment_donors, bins=30, color='lightblue', edgecolor='black')\naxes[1].axvline(mean_treatment, color='red', linestyle='--', label=f'Mean = ${mean_treatment:.2f}')\naxes[1].set_title('Treatment Group: Donation Amounts')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese plots visually confirm what your regression showed earlier: Although the treatment group received matching offers, they donated slightly less on average than the control group, conditional on donating. However, the distributions are quite similar overall, and the difference in means is not statistically significant.\nThis supports the idea that:\n“Matching offers increase the likelihood of giving, but do not meaningfully affect how much people give, once they’ve already decided to donate.”"
  },
  {
    "objectID": "blog/project1/index.html#simulation-experiment",
    "href": "blog/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nn = 500  # sample size per group\nreps = 10000  # number of simulations\n\n# Simulate samples\ndiffs = []\nfor _ in range(reps):\n    control_sample = np.random.binomial(1, p_control, n)\n    treatment_sample = np.random.binomial(1, p_treatment, n)\n    diff = treatment_sample.mean() - control_sample.mean()\n    diffs.append(diff)\n\n# Convert to array\ndiffs = np.array(diffs)\n\n# Plot histogram of differences\nplt.figure(figsize=(8, 4))\nplt.hist(diffs, bins=50, color='skyblue', edgecolor='black', density=True)\nplt.axvline(np.mean(diffs), color='red', linestyle='--', label=f'Mean Diff = {np.mean(diffs):.4f}')\nplt.title('Sampling Distribution of Mean Differences (p=0.022 vs p=0.018)')\nplt.xlabel('Treatment Mean - Control Mean')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTo illustrate key concepts in statistical inference, I conducted a simulation based on the charitable giving experiment.\nSimulation Setup We assume two groups:\nControl group: probability of donating is p=0.018\nTreatment group (offered any size of match): probability of donating is p=0.022\nIn each simulation, I generated 500 observations from each group using a Bernoulli distribution (i.e., a 0 or 1 outcome representing whether someone donates). I repeated this process 10,000 times and recorded the difference in sample means between the treatment and control groups in each replication.\nResults The histogram of the simulated mean differences shows a clear bell-shaped distribution centered near 0.004, which is the true difference in population probabilities.\nInterpretation The Law of Large Numbers is reflected in how the average of the simulated differences converges toward the true difference ( 0.022−0.018=0.004) as we increase the number of replications.\nThe Central Limit Theorem explains why the distribution of these sample differences is approximately normal, even though the underlying data are binary (non-normal). This justifies using t-tests and confidence intervals in practice.\n\nLaw of Large Numbers\n\n# Simulation parameters\np_control = 0.018\np_treatment = 0.022\nn_control = 100000\nn_treatment = 10000\nsimulations = 10000\n\n# Simulate draws\ncontrol_sample = np.random.binomial(1, p_control, n_control)\ntreatment_sample = np.random.binomial(1, p_treatment, n_treatment)\n\n# Draw 10,000 random pairs and calculate differences\ndiffs = []\nfor _ in range(simulations):\n    control_draw = np.random.choice(control_sample)\n    treatment_draw = np.random.choice(treatment_sample)\n    diffs.append(treatment_draw - control_draw)\n\n# Convert to array and compute cumulative average\ndiffs = np.array(diffs)\ncumulative_avg = np.cumsum(diffs) / np.arange(1, simulations + 1)\n\n# Plot cumulative average with reference line at true mean difference (0.004)\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average', color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title('Cumulative Average of Simulated Differences')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTo demonstrate the Law of Large Numbers (LLN) and reinforce the intuition behind the t-statistic, I simulated 100,000 binary outcomes from a control distribution with a probability of donation p=0.018, and 10,000 binary outcomes from a treatment distribution with p=0.022. These distributions represent the underlying probabilities of donation in each group from the original charitable giving experiment.\nFrom these two populations, I randomly drew 10,000 treatment–control pairs and computed the difference in outcomes for each pair. The plot above shows the cumulative average of these 10,000 differences, alongside the true difference in means (0.004) indicated by a red dashed line.\nWhat the Plot Shows\n\nThe cumulative average starts out noisy due to randomness in small samples.\nAs more differences are accumulated, the average stabilizes and converges toward the true population difference of 0.004.\nThis convergence visually confirms the Law of Large Numbers: with enough samples, the sample average approaches the expected value.\nIt also reinforces the foundation of the Central Limit Theorem — although each individual outcome is binary (not normally distributed), the sampling distribution of the mean becomes approximately normal.\n\nThe simulation shows that the cumulative average approaches the true difference in means between treatment and control groups. This not only demonstrates core statistical principles like the LLN and CLT, but also helps explain why test statistics like the t-statistic work reliably in large samples — even when the underlying data is not continuous or normally distributed.\n\n\nCentral Limit Theorem\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nreps = 1000\n\n# Set up plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\n# Loop over sample sizes and simulate mean differences\nfor i, n in enumerate(sample_sizes):\n    mean_diffs = []\n    for _ in range(reps):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        mean_diffs.append(diff)\n\n    # Plot histogram of mean differences\n    ax = axes[i]\n    ax.hist(mean_diffs, bins=30, color='skyblue', edgecolor='black', density=True)\n    ax.axvline(x=0, color='red', linestyle='--', label='Zero')\n    ax.axvline(x=np.mean(mean_diffs), color='blue', linestyle='-', label='Mean')\n    ax.set_title(f\"Sample Size: {n}\")\n    ax.set_xlabel(\"Mean Difference (Treatment - Control)\")\n    ax.set_ylabel(\"Density\")\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nInterpretation\n\nAt small sample sizes (n = 50): The distribution is wide and somewhat irregular. Zero lies close to the center, meaning we often can’t distinguish treatment from control.\nAs the sample size increases: The distributions become tighter, more symmetrical, and more normal-shaped — a direct illustration of the CLT.\nBy n = 500 or 1000: The distribution is clearly centered around the true mean difference (~0.004), and zero shifts toward the tail, suggesting we now have enough data to statistically distinguish treatment from control in many simulations.\n\nThese plots demonstrate the Central Limit Theorem in action: as the sample size grows, the sampling distribution of the mean difference becomes more normal and more concentrated around the true value. The probability of observing an effect near zero — assuming the true difference is 0.004 — shrinks with larger sample sizes, improving our ability to detect a real effect."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  }
]